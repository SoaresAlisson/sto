---
title: "Entities and relation extraction"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{entities_and_relation_extraction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(sto)
```

## Named Entity extraction and its relations

The package {sto} also provides a set of tools to extract entities and relations from text. It does so by one of the simples form: by using the rule based approach. It contains a rule based extraction algorithm and a rule based relation extraction algorithm.
For more advanced NER, there is other packages such as 
[{crfsuite}](https://cran.r-project.org/web/packages/crfsuite/index.html), {[UDpipe](https://cran.r-project.org/web/packages/udpipe/)} and {[spacyR](https://spacyr.quanteda.io/)}.
This functions do not work so well like the NER of the mentioned packages, but we think that, in some situations, they can be better job than joining unigram, bigrams, trigrams and so on.
Because it is a rule based approach, it is very simple to use and also fast. It will also requires a lot of cleaning, but you have the absolute control over which words are extracted and what words are rejected. 

In Natural Language Processing, to find proper names or terms that frequently appears together is called "collocation", e.g., to find "United Kingdom". You can learn more what is collocation and its statistical details and r function in this [article](https://sigil.r-forge.r-project.org/materials/04_collocation_analysis.pdf), and it is also possible to functions like [`quanteda.textstats::textstat_collocations()`](https://quanteda.io/reference/textstat_collocations.html), [`TextForecast::get_collocations()`](https://cran.r-project.org/web/packages/TextForecast/) to identify them, but it also will require a lot of data cleaning, specially if you want is proper names.

How it works?  
The function captures all words that:   
- begins with uppercase,   
- followed by other uppercases, lowercase or numbers, without white space  
- it can contain symbols like `_`, `-` or `.`.

In this way, words like "Covid-19" are also captured
In languages such as English and Portuguese, it extracts proper names. In German, it also extracts nouns.

There is some trade-off, of course.
It will capture a lot of undesired words and will demand posterior cleaning, like:  
- It does not contain any sort of built-in classification.  
- "Obama Chief of Staff Rahm Emanuel" will be captured as one entity, what is not wrong et al, but maybe not what was expect.

The downsides are 

 It will not capture:
- entities that begin with lowercase

In my experience, this approach works better to certain types of text than others. Books, formal articles can be a good option that works well with this function. Text from social media, because it lacks formalities of the language and have a lot of types, it will not work so well.

So, let's extract some proper names from a simple text:

```{r NER}
"John Does lives in New York in United States of America." |> extract_entity()
```

Or it is possible to use other languages, specifying the parameter `connectors` using the function `connectors(lang)`. Checking the connectors:

```{r}
connectors("eng")
connectors("pt")
connectors("port")

# by default, the functions uses the parameter "misc". meaning "miscellaneous".
connectors("misc")
```

Using with other languages:

```{r NER pt}
"João Ninguém mora em São José do Rio Preto. Ele esteve antes em Sergipe" |>
  extract_entity(connect = connectors("pt"))

vonNeumann_txt <- "John von Neumann (/vɒn ˈnɔɪmən/ von NOY-mən; Hungarian: Neumann János Lajos [ˈnɒjmɒn ˈjaːnoʃ ˈlɒjoʃ]; December 28, 1903 – February 8, 1957) was a Hungarian and American mathematician, physicist, computer scientist and engineer"
vonNeumann_txt |> extract_entity()
```




## Extracting a graph
It is possible to extract a graph from the extracted entities. First, happens the tokenization by sentence or paragraph.
Than, the entities are extracted using `extract_entity()`. Than a data frame with the co-occurrence of words in sentences or paragraph is build. 

```{r vonNeumann graph}
vonNeumann_txt |> extract_graph()
```

This process can take a while to run if the text/corpus is big. So, if you are interested only in some words, so first of all, filter the sentences/paragraphs with the desired words, and after that, extract the graph.
Seeing another example, extracting from a wikipedia article:

```{r ex wikipedia scrape GNU}
page <- "https://en.wikipedia.org/wiki/GNU_General_Public_License" |> rvest::read_html()
text <- page |>
  rvest::html_nodes("p") |>
  rvest::html_text()
# looking at the scraped text:
text[1:2] # seeing the head of the text
```

And now extracting the graphs:

```{r ex wikipedia plot GNU}
g <- text |> extract_graph(sw = gen_stopwords("en", include = "The This It"))
g
g_N <- g |> dplyr::count(n1, n2, sort = T)
g_N
```

```{r ploting the graph}
plot_graph(text, g_N)
```

To plot an interactive graph, it is possible to use {networkD3}:

```{r networkD3}
g_N |>
  head(100) |> # to reduce the amount of nodes and edges in the graph
  networkD3::simpleNetwork(
    height = "10px", width = "30px",
    linkDistance = 50,
    fontSize = 16
  )
```

Another text example.
<!-- "https://en.wikipedia.org/wiki/Julia_Silge" -->
```{r ex2 wiki Hurricane}
page <- "https://en.wikipedia.org/wiki/Hurricane_Milton" |> rvest::read_html()
text <- page |>
  rvest::html_nodes("p") |>
  rvest::html_text()
text[1:2] # seeing the head of the tex
g <- text |> extract_graph(sw = gen_stopwords("en", include = "The This It"))
g_N <- g |> dplyr::count(n1, n2, sort = T)

plot_graph(text, g_N, head_n = 50)
```
To plot an interactive graph, it is possible to use {networkD3}:

```{r networkD3 hurricane}
g_N |>
  head(100) |> # to reduce the amount of nodes and edges in the graph
  networkD3::simpleNetwork(
    height = "10px", width = "30px",
    linkDistance = 50,
    fontSize = 16
  )
```





